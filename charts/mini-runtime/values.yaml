mongo:
  aktoMongoConn: ""

kubernetesClusterDomain: cluster.local

# Node scheduling configuration
nodeSelector: {}
  # Example usage:
  # nodetype: coreservices

tolerations: []
  # Example usage:
  # - key: nodetype
  #   operator: Equal
  #   value: coreservices
  #   effect: NoSchedule

affinity: {}
  # Example usage:
  # nodeAffinity:
  #   requiredDuringSchedulingIgnoredDuringExecution:
  #     nodeSelectorTerms:
  #     - matchExpressions:
  #       - key: nodetype
  #         operator: In
  #         values:
  #         - coreservices

mini_runtime:
  # External Kafka Configuration
  # Set useExternalKafka to true to use an existing Kafka cluster
  # When enabled, the internal Kafka container will not be deployed
  useExternalKafka: false
  externalKafka:
    # Kafka broker URL (e.g., kafka.example.com:9092 or kafka1:9092,kafka2:9092,kafka3:9092)
    brokerUrl: ""
    # SASL authentication (leave empty for no authentication)
    username: ""
    password: ""

  aktoApiSecurityRuntime:
    env:
      aktoAccountName: Helios
      aktoConfigName: staging
      aktoInstanceType: DASHBOARD
      aktoKafkaBrokerMal: localhost:29092
      aktoKafkaBrokerUrl: 127.0.0.1:29092
      aktoKafkaGroupIdConfig: asdf
      aktoKafkaMaxPollRecordsConfig: "100"
      aktoKafkaTopicName: akto.api.logs
      aktoTrafficBatchSize: "100"
      aktoTrafficBatchTimeSecs: "10"
      aktoLogLevel: WARN
      puppeteerReplayServiceUrl: http://akto-puppeteer-replay:3000
      useHostName: true
      databaseAbstractorUrl: https://cyborg.akto.io
      # If you want to use secrets to store database abstractor token. default: false
      useSecretsForDatabaseAbstractorToken: false
      # If not using secrets, place token here.
      databaseAbstractorToken: ""
      # If using secrets, place token here.
      databaseAbstractorTokenSecrets: 
        # Name of an existing secret containing the Database Abstractor Token
        existingSecret: ""
        # Token to use if existingSecret is not provided
        token: ""
    image:
      repository: public.ecr.aws/aktosecurity/akto-api-security-mini-runtime
      tag: 1.54.4_local
    imagePullPolicy: Always
    resources:
      requests:
        cpu: 2
        memory: "4Gi"
      limits:
        cpu: 2
        memory: "8Gi"
  kafka1:
    env:
      # add advertised listeners if you want to override the default listeners
      kafkaAdvertisedListeners: ""
      kafkaBrokerId: "1"
      kafkaCleanupPolicy: delete
      kafkaCreateTopics: akto.api.logs:3:3
      kafkaInterBrokerListenerName: LISTENER_DOCKER_EXTERNAL_LOCALHOST
      kafkaListenerSecurityProtocolMap: CONTROLLER:PLAINTEXT,LISTENER_DOCKER_EXTERNAL_LOCALHOST:PLAINTEXT,LISTENER_DOCKER_EXTERNAL_DIFFHOST:PLAINTEXT
      kafkaListenerSecurityProtocolMapSsl: CONTROLLER:PLAINTEXT,LISTENER_DOCKER_EXTERNAL_LOCALHOST:PLAINTEXT,LISTENER_DOCKER_EXTERNAL_DIFFHOST:PLAINTEXT,LISTENER_DOCKER_EXTERNAL_DIFFHOST_ENCRYPTED:SSL
      kafkaListenerSecurityProtocolMapSasl: CONTROLLER:PLAINTEXT,LISTENER_DOCKER_EXTERNAL_DIFFHOST_SASL:SASL_PLAINTEXT,LISTENER_DOCKER_EXTERNAL_LOCALHOST_SASL:SASL_PLAINTEXT,LISTENER_DOCKER_EXTERNAL_LOCALHOST:SASL_PLAINTEXT,LISTENER_DOCKER_EXTERNAL_DIFFHOST:SASL_PLAINTEXT
      kafkaListenerSecurityProtocolMapSaslTls: CONTROLLER:PLAINTEXT,LISTENER_DOCKER_EXTERNAL_DIFFHOST_SASL:SASL_SSL,LISTENER_DOCKER_EXTERNAL_LOCALHOST_SASL:SASL_PLAINTEXT
      kafkaProcessRoles: "broker,controller"
      kafkaNodeId: "1"
      kafkaControllerQuorumVoters: "1@localhost:9094"
      kafkaControllerListenerNames: "CONTROLLER"
      kafkaListeners: ""
      kafkaLogCleanerEnable: "true"
      kafkaLogRetentionBytes: "10737418240"
      kafkaLogRetentionCheckIntervalMs: "60000"
      kafkaLogRetentionHours: "5"
      kafkaLogSegmentBytes: "104857600"
      kafkaOffsetsTopicReplicationFactor: "1"
      kafkaTransactionStateLogMinIsr: "1"
      kafkaTransactionStateLogReplicationFactor: "1"
      kafkaClusterId: "c6a1b8e2-4f2a-4b2a-9c3f-1a2b3c4d5e6f"
      sslKeystoreLocation: "/etc/kafka/ssl/secrets/server.keystore.jks"
      sslKeystorePassword: "password"
      sslKeyPassword: "password"
      sslTruststoreLocation: "/etc/kafka/ssl/secrets/server.truststore.jks"
      sslTruststorePassword: "password"
      sslBaseMountPath: "/etc/kafka/ssl/secrets"
      sslSecretName: "kafka-certs"
      useSecretsForSaslCredentials: false
      saslCredentialsSecrets:
        existingSecret: ""
        username: ""
        password: ""
      saslUsername: ""
      saslPassword: ""
    useTls: false
    useSasl: false
    image:
      repository: public.ecr.aws/aktosecurity/confluentinc-cp-kafka
      tag: 8.1.1-1-ubi9
    resources:
      requests:
        cpu: 1.5
        memory: "4Gi"
        ephemeral-storage: "500Mi"
      limits:
        cpu: 1.5
        memory: "8Gi"
        ephemeral-storage: "11Gi"

  replicas: 1
  type: ClusterIP
  annotations:
    service.beta.kubernetes.io/aws-load-balancer-internal: "true"

keel:
  keel:
    env:
      awsAccessKeyId: ""
      awsRegion: ""
      awsSecretAccessKey: ""
      hipchatApprovalsBotName: ""
      hipchatApprovalsChannel: ""
      hipchatApprovalsPasswort: ""
      hipchatApprovalsUserName: ""
      hipchatChannels: ""
      hipchatToken: ""
      insecureRegistry: "true"
      mattermostEndpoint: ""
      notificationLevel: info
      webhookEndpoint: ""
    image:
      repository: public.ecr.aws/aktosecurity/keelhq-keel
      tag: akto_v1.0.0
    imagePullPolicy: IfNotPresent
    enabled: true
    resources:
      limits:
        cpu: 100m
        memory: 128Mi
      requests:
        cpu: 50m
        memory: 64Mi
  maxUnavailable: 1
  ports:
  - name: keel
    port: 9300
    protocol: TCP
    targetPort: 9300
  replicas: 1
  serviceAccount:
    annotations: {}
  type: LoadBalancer

ports:
  default:
    - port: 9092
      targetPort: 9092
  tls:
    - name: plaintext
      port: 9092
      targetPort: 9092
    - name: ssl
      port: 9093
      targetPort: 9093
  sasl:
    - name: sasl-plaintext
      port: 9092
      targetPort: 9092
    - name: sasl-ssl
      port: 9093
      targetPort: 9093

threat_client:
  replicas: 1
  aktoApiSecurityThreatClient:
    env:
      enabled: true
      aggregationRulesEnabled: true
      postgresUrl: jdbc:postgresql://postgres.default.svc.cluster.local:5432/akto
      postgresUser: akto
      postgresPassword: akto
      aktoAccountName: Helios
      aktoConfigName: staging
      aktoInstanceType: DASHBOARD
      backendUrl: https://tbs.akto.io
      aktoLogLevel: WARN
      useHostName: true
    image:
      repository: aktosecurity/akto-threat-detection
      tag: "1.6.7"
    imagePullPolicy: Always
    resources:
      requests:
        cpu: 1.5
        memory: "1Gi"
      limits:
        cpu: 1.5
        memory: "2Gi"

redis:
  image:
    repository: redis
    tag: "7.0"
    pullPolicy: IfNotPresent
  resources:
    requests:
      cpu: "500m"
      memory: "500Mi"
    limits:
      cpu: "900m"
      memory: "1500Mi"
  persistence:
    enabled: false
    size: "2Gi"
    storageClass: ""

fluent-bit:
  enabled: true
  kind: DaemonSet
  
  image:
    repository: cr.fluentbit.io/fluent/fluent-bit
    pullPolicy: IfNotPresent

  serviceAccount:
    create: true

  rbac:
    create: true

  flush: 1
  metricsPort: 2020
  logLevel: debug

  config:
    service: |
      [SERVICE]
          Daemon Off
          Flush {{ .Values.flush }}
          Log_Level {{ .Values.logLevel }}
          Parsers_File /fluent-bit/etc/parsers.conf
          Parsers_File /fluent-bit/etc/conf/custom_parsers.conf
          HTTP_Server On
          HTTP_Listen 0.0.0.0
          HTTP_Port {{ .Values.metricsPort }}
          Health_Check On
          storage.path          /var/log/flb-storage/
          storage.keep.rejected on
          storage.rejected.path rejected

    inputs: |
      [INPUT]
          Name tail
          Path /var/log/containers/akto-mini-runtime-mini-runtime-*_akto-api-security-runtime-*.log
          Alias tail_runtime
          multiline.parser docker, cri
          Tag kube.*
          Mem_Buf_Limit 5MB
          Skip_Long_Lines On
          Refresh_Interval 5
          DB /var/fluent-bit/state/flb_kube.db
          Read_from_Head On

    filters: |
      [FILTER]
          Name kubernetes
          Match kube.*
          Kube_URL https://kubernetes.default.svc:443
          Kube_CA_File /var/run/secrets/kubernetes.io/serviceaccount/ca.crt
          Kube_Token_File /var/run/secrets/kubernetes.io/serviceaccount/token
          Merge_Log On
          Keep_Log Off
          K8S-Logging.Parser On
          K8S-Logging.Exclude On
          Labels Off
          Annotations Off

      [FILTER]
          Name lua
          Match kube.*
          script /fluent-bit/etc/conf/extract_account.lua
          call extract_account_id

    outputs: |
      [OUTPUT]
          Name http
          Match kube.*
          Host observability.akto.io
          Port 443
          URI /logs
          Format json
          Header Authorization Bearer eyJhbGciOiJSUzI1NiJ9.eyJpc3MiOiJBa3RvIiwic3ViIjoiaW52aXRlX3VzZXIiLCJhY2NvdW50SWQiOjE3NTY4NDQ3MDEsImlhdCI6MTc2NTM3OTUwNywiZXhwIjoxNzgxMTA0MzA3fQ.W61v2oJOg55bXV3Du1df7nBaiPeah31fqtwiJAms6dOqHAk0GQwVBhXXBmdfMwl2ptWUwwbfZ7q1T9kf5wouu60uGLQPFeg_rfnkSXs0IoOVTARqEEYCJ0rEjT_Sw3_L6zu5kTaDJPXivMkcbvVIxf868GZ9Wm0diyGd-5kGE2B8dGat9uhgjFzQJ9dwF0HrSHYZCloCynKzO0WjE8YxW3WRa1ZqBEmmqVwsFysqLFGG0FZIscgp9HfRQP5zVavg-vHgDN5wZNsXGyp3urIs48njiY7AQkdNr_aXYs9_Q-FD8pXGOpbKM1OYP8WrRkVjrNz6b0FB2mFqsafHhtPzpw
          tls On
          tls.verify On
          net.keepalive on
          net.keepalive_idle_timeout 30
          retry_limit 3

      [OUTPUT]
          Name stdout
          Match kube.*
          Format json_lines

    customParsers: |
      [PARSER]
          Name docker_no_time
          Format json
          Time_Keep Off
          Time_Key time
          Time_Format %Y-%m-%dT%H:%M:%S.%L

    extraFiles:
      extract_account.lua: |
        function extract_account_id(tag, timestamp, record)
            local log = record["log"]
            if log ~= nil then
                local account_id = string.match(log, "accountId[%s:]+(%d+)")
                if account_id == nil then
                    account_id = string.match(log, "acc[%s:]+(%d+)")
                end
                if account_id ~= nil then
                    record["log_account_id"] = account_id
                end
            end
            return 1, timestamp, record
        end

  volumeMounts:
    - name: config
      mountPath: /fluent-bit/etc/conf

  daemonSetVolumes:
    - name: varlog
      hostPath:
        path: /var/log
    - name: varlibdockercontainers
      hostPath:
        path: /var/lib/docker/containers
    - name: etcmachineid
      hostPath:
        path: /etc/machine-id
        type: File
    - name: state
      emptyDir: {}

  daemonSetVolumeMounts:
    - name: varlog
      mountPath: /var/log
    - name: varlibdockercontainers
      mountPath: /var/lib/docker/containers
      readOnly: true
    - name: etcmachineid
      mountPath: /etc/machine-id
      readOnly: true
    - name: state
      mountPath: /var/fluent-bit/state